:scrollbar:
:data-uri:
:toc2:
:icons: images/icons

== Managing Security

:numbered:

In this lab you manage the various security features of OpenShift Enterprise.

* Allow Users to Run Privileged Containers
* Create SCCs to Manage Permissions
* Manage Project Self-Provisioning

== Allow Users to Run Privileged Containers

Here you add a user to the privileged SCC to let the user run a privileged container.

=== Authenticate to OpenShift Enterprise and Choose Your Project

. Connect to the OpenShift Enterprise `master` following the same steps you used in previous labs.
. Authenticate to OpenShift Enterprise as user `marina` .
+
----

[root@master00 ~]# su - marina
[marina@master00 ~]$ guid=`hostname|cut -f2 -d-|cut -f1 -d.`
[marina@master00 ~]$ oc login -u marina --insecure-skip-tls-verify --server=https://master00-${guid}.oslab.opentlc.com:8443

----

* You will see the following:
+
----
Password: (Enter r3dh4t1!)
Login successful.
Welcome to OpenShift! See 'oc help' to get started.
----

. Create the `managesecurity-lab` project in which to work.
+
----
[marina@master00 ~]$ oc new-project managesecurity-lab

----

=== Create the Privileged Pod Definition

. Create the `hello-pod-priv.json` file. 
* Note the `"privileged": true` setting.
+
----

[marina@master00 ~]$ cat <<EOF > hello-pod-priv.json
{
  "kind": "Pod",
  "apiVersion": "v1",
  "metadata": {
    "name": "hello-openshift",
    "creationTimestamp": null,
    "labels": {
      "name": "hello-openshift"
    }
  },
  "spec": {
    "containers": [
      {
        "name": "hello-openshift",
        "image": "openshift/hello-openshift:v0.4.3",
        "ports": [
          {
            "containerPort": 8080,
            "protocol": "TCP"
          }
        ],
        "resources": {
          "limits": {
            "cpu": "10m",
            "memory": "16Mi"
          }
        },
        "terminationMessagePath": "/dev/termination-log",
        "imagePullPolicy": "IfNotPresent",
        "capabilities": {},
        "securityContext": {
          "capabilities": {},
          "privileged": true
        },
        "nodeSelector": {
          "region": "primary"
        }
      }
    ],
    "restartPolicy": "Always",
    "dnsPolicy": "ClusterFirst",
    "serviceAccount": ""
  },
  "status": {}
}

EOF

----

. Try to create the pod from the `hello-pod-priv.json` definition file, and note that it fails.
+
----
[marina@master00-GUID ~]$ oc create -f hello-pod-priv.json
Error from server: Pod "hello-openshift" is forbidden: unable to validate against any security context constraint: [provider restricted: .spec.containers[0].securityContext.privileged: invalid value 'true': Privileged containers are not allowed]
----


=== Add a User to the Privileged SCC

One way to let user `marina` deploy privileged containers is to add her to the `privileged` SCC.

. As `root`, display the available SCCs:
+
----
[root@master00 ~]# oc get scc
NAME         PRIV      CAPS      HOSTDIR   SELINUX     RUNASUSER
privileged   true      []        true      RunAsAny    RunAsAny
restricted   false     []        false     MustRunAs   MustRunAsRange
----

. Edit the `privileged` SCC to look similar to the sample below.
. Add `- marina` as the last line of the file. 
+
[NOTE]
To clarify, this means entering *-<space>marina*.
+
----
[root@master00 ~]# oc edit scc privileged
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
allowHostDirVolumePlugin: true
allowPrivilegedContainer: true
apiVersion: v1
groups:
- system:cluster-admins
- system:nodes
kind: SecurityContextConstraints
metadata:
  creationTimestamp: 2015-07-30T02:46:22Z
  name: privileged
  resourceVersion: "5104"
  selfLink: /api/v1/securitycontextconstraints/privileged
  uid: 29c38820-3665-11e5-9899-2cc260072896
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: RunAsAny
users:
- system:serviceaccount:openshift-infra:build-controller
- marina
----

=== Try to Deploy the Pod Again

. Go back to user `marina` and test your new privileges.
+
----
[marina@master00-GUID ~]$ oc create -f hello-pod-priv.json
----

* The pod should deploy this time.

. Clean up the environment so you can try another way of granting user permissions. 
.. As user `marina`, delete the pod you created.
+
----
[marina@master00-GUID ~]$ oc delete -f hello-pod-priv.json
----

.. As `root`, remove `marina` from the `privileged` SCC by deleting `- marina` from the last line of the file.
+
----
[root@master00 ~]# oc edit scc privileged
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
allowHostDirVolumePlugin: true
allowPrivilegedContainer: true
apiVersion: v1
groups:
- system:cluster-admins
- system:nodes
kind: SecurityContextConstraints
metadata:
  creationTimestamp: 2015-07-30T02:46:22Z
  name: privileged
  resourceVersion: "5104"
  selfLink: /api/v1/securitycontextconstraints/privileged
  uid: 29c38820-3665-11e5-9899-2cc260072896
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: RunAsAny
users:
- system:serviceaccount:openshift-infra:build-controller

----

== Create SCCs to Manage Permissions

You do not always want to add users directly to the very permissive `privileged` SCC. Here you create a few SCCs to control your users' permissions and capabilities.

=== Create SCCs to Allocate Permissions and Capabilities

First you create an SCC to let specific users run privileged containers.

. Create the `scc-ops` SCC.

+
[source,yaml]
----
cat << EOF > scc-ops.yaml
kind: SecurityContextConstraints
apiVersion: v1
metadata:
  name: scc-ops
allowPrivilegedContainer: true
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: RunAsAny
users:
- marina

EOF

----
+
[NOTE]
This is different from the built-in `privileged` SCC. It is more restrictive in that it does not allow users to mount local host directories with `allowHostDirVolumePlugin`.

. After saving the file, use `oc create` to create the SCC.
+
----
[root@master00 ~] oc create -f scc-ops.yaml

----


. Check your available SCCs.
+
----

[root@master00 ~]# oc get scc
NAME         PRIV      CAPS      HOSTDIR   SELINUX     RUNASUSER
privileged   true      []        true      RunAsAny    RunAsAny
restricted   false     []        false     MustRunAs   MustRunAsRange
scc-ops      true      []        false     RunAsAny    RunAsAny

----


. Create the `scc-dev` SCC.

* This SCC is for the Red Hat developer team, letting them create Docker builds that use any user _other than root_.

* In this lab, you take another approach to achieve the same result. You `oc export` the `restricted` built-in SCC and make changes to it.
+
[source,yaml]
----
[root@master00 ~] oc export scc restricted | tee scc-dev.yaml
apiVersion: v1
groups:
- system:authenticated
kind: SecurityContextConstraints
metadata:
  creationTimestamp: null
  name: restricted
runAsUser:
  type: MustRunAsRange
seLinuxContext:
  type: MustRunAs
----

. Edit the file as follows:
.. Delete the `groups` section.
.. Change `RunAsUser` type value to `MustRunAsNonRoot`.
.. Change the SCC `name` to `scc-dev`.
.. Add the `users` section, and make sure user `andrew` is on the list
+
[source,yaml]
----
apiVersion: v1
kind: SecurityContextConstraints
metadata:
  creationTimestamp: null
  name: scc-dev
runAsUser:
  type: MustRunAsNonRoot
seLinuxContext:
  type: MustRunAs
users:
 - andrew
----

. After saving the file, use `oc create` to create the SCC.
+
----
[root@master00 ~] oc create -f scc-dev.yaml

----

. Check your available SCCs.
+
----
[root@master00-GUID ~]# oc get scc
NAME         PRIV      CAPS      HOSTDIR   SELINUX     RUNASUSER
privileged   true      []        true      RunAsAny    RunAsAny
restricted   false     []        false     MustRunAs   MustRunAsRange
scc-ops      true      []        false     RunAsAny    RunAsAny
scc-dev      false     []        false     MustRunAs   MustRunAsNonRoot
----

=== Test Your New SCCs

. Go back to user `marina`, and test your new privileges.
+
----
[marina@master00-GUID ~]$ oc create -f hello-pod-priv.json
----

. Confirm that your pod deployed.

== Manage Project Self-Provisioning

Here you disable self-provisioning for all users and then let specific users self-provision projects from a set template.

=== Disable Self-Provisioning

. Disable self-provisioning for the `system:authenticated` group.
.. As `root`, use `oc edit` to edit the `clusterPolicybinding`.
+
----
 [root@master00-GUID ~]$ oc edit clusterPolicybinding :default
----
+
.. Your `self-provisioners` binding will have the `system:authenticated` group listed and will look similar to the following:
+
[source,yaml]
----
- name: self-provisioners
  roleBinding:
    groupNames:
    - system:authenticated
    metadata:
      creationTimestamp: 2015-08-10T06:40:30Z
      name: self-provisioners
      resourceVersion: "44"
      uid: b18cdc05-3f2a-11e5-a361-2cc260072896
    roleRef:
      name: self-provisioner
    userNames: []
----

.. Remove the line with the `system:authenticated` group. 

* The `self-provisioners` binding should now look like the following:
+
[source,yaml]
----
- name: self-provisioners
  roleBinding:
    groupNames:
    metadata:
      creationTimestamp: 2015-08-10T06:40:30Z
      name: self-provisioners
      resourceVersion: "44"
      uid: b18cdc05-3f2a-11e5-a361-2cc260072896
    roleRef:
      name: self-provisioner
    userNames: []
----

. To create a message for users trying to provision projects, edit the `master` config file `/etc/origin/master/master-config.yaml` by changing the `projectRequestMessage` key to your own message.
+
----
  projectRequestMessage: "Please create project using the portal http://portal.example.com/provision or Contact Mike"
----

. Restart the OpenShift Enterprise `master` daemon.
+
----
[root@master00-GUID ~]$ systemctl restart openshift-master
----

=== Allow Specific Users Self-Provisioning From the Project Template

. Create a user for your new hire `mike`. 

* You will use this user to create projects for all users in the environment.
+
----
[root@master00-GUID ~]# useradd mike
[root@master00-GUID ~]# htpasswd -b /etc/openshift/openshift-passwd mike r3dh4t1!
----

. Add the `self-provisioner` role to user `mike`.
+
----
[root@master00-GUID ~]# oadm policy add-cluster-role-to-user self-provisioner mike
----

. Log in as user `marina` and see if you can create a project. You will not be able to.
+
----
[root@master00-GUID ~]# su - marina
Last login: Wed Aug 12 02:19:02 EDT 2015 on pts/1
[marina@master00-GUID ~]$ oc new-project notgoingtowork
Error from server: Please create project using the portal http://portal.example.com/provision


----
. As user `mike`, log in to OpenShift Enterprise.
. See if you can create a project and allocate `marina` as the administrator.
+
----
[root@master00-GUID ~]# su - mike
Last login: Wed Aug 12 02:20:02 EDT 2015 on pts/1
[mike@master00-d9b2 ~]$ oc new-project thiswillwork
Now using project "thiswillwork" on server "https://localhost:8443"
----
+
[NOTE]
If you already logged in as a different user, you might need to use `oc login` to refresh the token.

. Look at the project that `mike` created. 

* Note that the `Node Selector` is not defined.
+
----
[mike@master00-GUID ~]$ oc describe project thiswillwork
Name:           thiswillwork
Created:        8 minutes ago
Labels:         <none>
Annotations:    openshift.io/description=
                openshift.io/display-name=
                openshift.io/sa.scc.mcs=s0:c8,c7
                openshift.io/sa.scc.uid-range=1000070000/10000
Display Name:   <none>
Description:    <none>
Status:         Active
Node Selector:  <none>

Quota:  <none>

Resource limits:        <none>

----

. Limit all users (including `mike`, but excluding `cluster administrator` users) to being able to deploy projects only in the `primary` region.

.. As `root`, create a project template definition file.

* Note that the desired `node-selector` is set.
+
[source,yaml]
----
[root@master00-GUID ~]# echo '
apiVersion: v1
kind: Template
metadata:
  name: project-request
  namespace: openshift
objects:
- apiVersion: v1
  displayName: ${PROJECT_DISPLAYNAME}
  kind: Project
  metadata:
    annotations:
      description: ${PROJECT_DESCRIPTION}
      displayName: ${PROJECT_DISPLAYNAME}
      openshift.io/node-selector: region=primary
    creationTimestamp: null
    name: ${PROJECT_NAME}
  spec: {}
  status: {}
- apiVersion: v1
  groupNames: []
  kind: RoleBinding
  metadata:
    creationTimestamp: null
    name: admins
    namespace: ${PROJECT_NAME}
  roleRef:
    name: admin
  userNames:
  - ${PROJECT_ADMIN_USER}
parameters:
- name: PROJECT_NAME
- name: PROJECT_DISPLAYNAME
- name: PROJECT_DESCRIPTION
- name: PROJECT_ADMIN_USER
' > project-request.yaml
----


.. As `root`, load the template into the `openshift` project.
+
----
[root@master00-GUID ~]# oc create -f project-request.yaml --namespace=openshift
----

.. To set the default template, edit the `master` config file `/etc/origin/master/master-config.yaml`, and change the `projectRequestTemplate` key value to `openshift/project-request`.
+
----
[root@master00-GUID ~]# vi /etc/origin/master/master-config.yaml
or
[root@master00-GUID ~]# sed -i 's/projectRequestTemplate: ""/projectRequestTemplate: "openshift\/project-request"/g' /etc/origin/master/master-config.yaml
----

* The line should look something like this:
+
----
  projectRequestTemplate: "openshift/project-request"
----

. Restart the `master` daemon.
+
----
[root@master00-GUID ~]# systemctl restart openshift-master
----


. As user `mike`, try to create another project.
+
----
[mike@master00-GUID ~]$ oc new-project thiswillworkbetter
Now using project "thiswillworkbetter" on server "https://localhost:8443".
----

. Check if the project template defines the `Node Selector`.
+
----
[mike@master00-GUID ~]$ oc describe project thiswillworkbetter
Name:           thiswillworkbetter
Created:        8 seconds ago
Labels:         <none>
Annotations:    displayName=
                openshift.io/display-name=
                openshift.io/node-selector=region=primary
                openshift.io/sa.scc.mcs=s0:c10,c0
                openshift.io/sa.scc.uid-range=1000090000/10000
Display Name:   <none>
Description:    <none>
Status:         Active
Node Selector:  region=primary

Quota:  <none>

Resource limits:        <none>
----

. To make user `marina` the administrator on the project, bind the `admin` role to her.
+
----
[mike@master00-GUID ~]$ oc policy add-role-to-user admin marina -n thiswillworkbetter
----

. As `marina`, check that you have access to the `thiswillworkbetter` project.
+
----

[root@master00-GUID ~]# su - marina
Last login: Wed Aug 12 02:29:14 EDT 2015 on pts/1
[marina@master00-GUID ~]$ oc get project
NAME                 DISPLAY NAME   STATUS
thiswillworkbetter                  Active


----
