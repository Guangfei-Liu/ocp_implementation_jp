:noaudio:

ifdef::revealjs_slideshow[] 

[#cover,data-background-image="image/1156524-bg_redhat.png" data-background-color="#cc0000"] 
== &nbsp;


[#cover-h1] 
Red Hat OpenShift Enterprise Implementation

[#cover-h2] 
Architecture

[#cover-logo] 
image::{revealjs_cover_image}[] 

endif::[]




:numbered!:
:scrollbar:
:data-uri:

== Module Topics

* Overview and design concepts in OpenShift Enterprise v3 
* Introduction to Docker
* Introduction to Kubernetes infrastructure 
* Networking in OpenShift Enterprise v3
* Image registry 
* Builds and OpenShift STI images


ifdef::showscript[]

=== Transcript
Welcome to Module 2 of the OpenShift Enterprise Implementation course.

This module presents the following topics:

* Overview and design concepts in OpenShift Enterprise v3, including the OpenShift stack, how OpenShift works, standards, important projects, and how the various components work together.
    
* An introduction to Docker, including the difference between containers and VMs and Docker components and capabilities.

* An introduction to Kubernetes infrastructure, covering features and concepts with an emphasis on pods. 
 
* An Overview of Networking in OpenShift Enterprise v3, 

* The Image registry is described, including the integrated OpenShift Enterprise registry and third-party registries.
 
* And the module ends with a discussion of Builds and OpenShift STI images, which explains what an STI build is and why to use it.

endif::showscript[]


:scrollbar:
:data-uri:

== What is OpenShift

* OpenShift is a Platform-as-a-Service (PaaS)
* Provides development environments on demand (self service)
* Provides languages, frameworks, runtimes, and databases (polyglot)
* Automates application lifecycle management (build, deploy, retire)
* Enables collaboration between developers on projects and components
* Uses industry standards


ifdef::showscript[]

=== Transcript

We begin this module with an overview of OpenShift Enterprise design concepts. 

OpenShift is a Platform-as-a-Service, or PaaS, which is based on industry standards. OpenShift provides development environments on-demand, it offers a range of languages, frameworks, runtimes and databases, and automates application lifecycle management.

OpenShift enables collaboration between developers on projects and components.


endif::showscript[]



:scrollbar:
:data-uri:
== OpenShift Enterprise v3 Stack

* Standard containers API
* Container-optimized OS
* Web-scale orchestration
* Expanded services choices
* Enhanced user experience
* Community-driven innovation
* Industry-standard PaaS stack
+
image::images/OpenShiftStack.png[]


ifdef::showscript[]

=== Transcript

The OpenShift v3  stack, features the following: 

* Standard containers API
* Container-optimized OS
* Web-scale orchestration
* Expanded choice of services
* Enhanced user experience
* Community-driven innovation
* And uses an industry-standard PaaS stack.


endif::showscript[]



:scrollbar:
:data-uri:
== How OpenShift Works

* *Containers* - Run languages/framework middleware, database, and other runtimes
* *Pods* - Run one or more containers as single unit
* *Nodes* - Linux container hosts; run pods assigned by master
* *Master* - Provides API, service orchestration, scheduling and placement, maintains state, and manages pods and services
+
image::images/OpenShiftV3Arch.png[]


ifdef::showscript[]

=== Transcript

Here is a simplified explanation of some of the components of OpenShift v3:
Containers run languages and frameworks, middleware components, databases, and other runtimes. Pods run one or more containers as a single unit. 
Each pod has an IP and mapped storage volumes.

Nodes are Linux container hosts that run pods assigned by the master. 
The master provides API, service orchestration, scheduling and placement. It also maintains state and manages pods and services.
	

endif::showscript[]




:scrollbar:
:data-uri:
== Containerization Standards

.Isolation with Linux containers
* Isolate applications on host operating system
* Security
* Portability across host systems

.Container format with Docker
* Interface for communications, configuration, data persistence, provisioning
* Content agnostic
* Infrastructure agnostic

.Orchestration with Kubernetes
* Orchestrate containers at scale
* Define application topologies
* Handle container networking
* Manage container state
* Schedule across hosts

.Registry and container discovery
* Find and consume trusted container images
* Federate consumption libraries
* Promote consistency and reuse

ifdef::showscript[]

=== Transcript
Red Hat works with the open source community to drive standards for containerization. The main areas are:
 
* Isolation with Linux containers - Isolating applications on the host operating system, security, and portability across host systems.

* Container format with Docker - Docker is the interface for communications, configuration, data persistence, and provisioning. It is content and infrastructure agnostic.

* Orchestration with Kubernetes - Kubernetes orchestrates containers at scale; it defines application topologies, handles part of the container networking, manages container state, and it also schedules across hosts.
 
* Registry and container discovery - Red Hat promotes standards to easily find and consume trusted container images, to federate consumption libraries, and to promote consistency and reuse.

endif::showscript[]




:scrollbar:
:data-uri:
== Important Projects in OpenShift

* *Kubernetes* - link:http://kubernetes.io/[http://kubernetes.io/]

* *Docker* - http://docker.com or https://github.com/docker/docker
 
* *Etcd* - link:https://github.com/coreos/etcd[https://github.com/coreos/etcd]

+
image::images/ImportantProjects.png[]


ifdef::showscript[]

=== Transcript

OpenShift Enterprise v3 comprises several key open source projects, most notable are Kubernetes, Docker, and EtcD.   
Kubernetes orchestrates containers at massive scale and manages and orchestrates Docker containers across clusters of nodes.

Docker is an open source project that automates the deployment of applications inside software containers 
by providing an additional layer of abstraction and automation of operating-system-level virtualization. Docker provides the abstraction for packaging and creating lightweight containers.

EtcD is a highly available key-value store for shared configuration and service discovery. EtcD is the persistent data store for information about the OpenShift environment.  

OpenShift helps manage large developer organizations. OpenShift adds source code management, builds and deployments for developers; manages and promotes images at scale as they flow through the system, manages applications at scale, and tracks teams and users. 

endif::showscript[]



:scrollbar:
:data-uri:
== OpenShift Model

* *Masters* - Responsible for managing system state 

* *Nodes* - Act as agents to control containers, based on desired state defined by master
+
image::images/OpenShiftV3ArchFull.png[]


ifdef::showscript[]

=== Transcript

In OpenShift, hosts are classified into two separate yet equally important groups: masters and nodes.

Masters manage the state of the system, ensuring that all containers that should be running are running, and that other requests are serviced. 

OpenShift provides a REST endpoint for interacting with the system. All tools speak directly to the REST APIs - CLI, web console, IDE plug-ins, etc.
Multiple masters work together to provide high availability at the management layer.

Nodes act as agents to control containers based on the desired state defined by the master. Nodes provide an API endpoint and they handle management and synchronization between the components. 

Deployments may have several nodes. Nodes may be organized into many different topologies to suit the availability requirements of the workloads.



endif::showscript[]



:scrollbar:
:data-uri:
== OpenShift Workflow


.Simplified Workflow 
. User/automation calls REST API to change system state
. OpenShift Enterprise periodically reads the user’s desired state
. OpenShift Enterprise tries to sync other parts of system

.Example Scenario
* User predicts a traffic spike before a holiday 
* User wants more pods of specific service/application
* User decides to preemptively scale up to 6 app instances from 3 app instances.

.Process
. User calls to state: "this app should have 6 instances"
. Data store gets new information (desired scale = 6)
. In sync loop, replication controllers see mismatch between current scale (3) and desired scale (6). 
. OpenShift Enterprise schedules and deploys 3 instances (pods).


ifdef::showscript[]

=== Transcript

A simplified way of looking at the OpenShift Enterprise workflow would be: 

. Users or Automation make calls to the REST API (using the Web Console, Command line, any other method) to change the state of the system.
. OpenShift Enterprise periodically reads the user's desired state
. OpenShift Enterprise then tries to bring the other parts of the system into sync with the desired state.

For example, consider this scenario: An OpenShift Enterprise v3 user is predicting a spike in traffic before a holiday or major sports event. 
The user wants to spin up more pods of a specific service/application to accommodate the additional traffic.

Lets assume the application is currently configured with 3 running pods and the user wants to change that to 6 running pods as a pre-emptive measure.
The user then makes a call using the web console, CLI, or any other method to state that "this app should have 6 instances." 

At this point the data store gets updated with the new information indicating that the desired scale is 6 running pods.
On the next sync loop, the Replication Controllers, which will be explained later, determine that the current scale of 3 running pods does not match the desired scale of 6 running pods. 
This causes OpenShift Enterprise to schedule 3 more instances and place them for deployment.

As you can see, the OpenShift Enterprise controllers are performing the "business logic" of the system by taking user actions and transforming them into reality. 
You can customize how builds are run and launched independently of how images are managed, or how deployments happen.

endif::showscript[]




:scrollbar:
:data-uri:
== How it Works

.Service and Routing
* Takes care of internal and external requests from the applications running on OpenShift

+
image::images/01ServiceRouting.png[]


ifdef::showscript[]

=== Transcript

The service and routing layer takes care of internal and external requests from and to the applications running on OpenShift. 
A service provides a list of IPs for the pods it represents. The routing layer directs traffic from the outside world to the correct pod's IP and port. 

endif::showscript[]


:scrollbar:
:data-uri:
== How it Works

.Authentication
* Provides framework for collaboration and quota management
* Supports a number of mechanisms for authentication 
** Simplest use case for testing is `htpasswd`
+
image::images/02Authentication.png[]


ifdef::showscript[]

=== Transcript

The authentication layer provides a framework for collaboration and quota management. 
OpenShift Enterprise v3 supports a number of mechanisms for authentication. The simplest use case for testing purposes is `htpasswd`-based authentication.

endif::showscript[]





:scrollbar:
:data-uri:
== How it Works

.Store
* Holds current state, desired state, and configuration information in environment
+
image::images/03Store.png[]

ifdef::showscript[]

=== Transcript

The store layer holds the current state, the desired state, and configuration information about the environment.
 

endif::showscript[]




:scrollbar:
:data-uri:
== How it Works

.Replication
* Ensures number of instances/pods defined in store layer actually exist

+
image::images/04Replication.png[]

ifdef::showscript[]

=== Transcript

The replication layer and replication controller's role is to make sure that the number of instances/pods defined in the store layer actually exist.
The replication controller instantiates (creates) or kills pods according to the desired state definition.

endif::showscript[]


:scrollbar:
:data-uri:
== How it Works

.Scheduler
* Essentially the OpenShift Enterprise master 
* Determines where to create new pods

+
image::images/05Scheduler.png[]

ifdef::showscript[]

=== Transcript

The scheduler is essentially the OpenShift Enterprise master. Any time a pod needs to be created somewhere, the master determines where to do this. This is called "scheduling". 

endif::showscript[]



:scrollbar:
:data-uri:
== What is Docker

* *Docker* - Open platform for developers and admins to build, ship, and run distributed applications.

* Main support components:
** Docker Engine, a portable, lightweight runtime and packaging tool
** Docker Hub, a cloud service for sharing applications and automating workflows
* Benefits:
** Multi-version packaging format and isolation
** Simplified container API (Docker libcontainer)
** Easy to create (Dockerfile)
** Atomic deployment (Docker images)
** Large ecosystem (Docker Hub)



ifdef::showscript[]

=== Transcript

This next portion of the module provides an introduction to Docker.
Docker is an open platform for developers and system administrators to build, ship, and run distributed applications. The main components are the Docker Engine and the Docker hub. 
Docker Engine is a portable, lightweight runtime and packaging tool. Docker Hub is a cloud service for sharing applications and automating workflows.

Docker has a number of benefits, as shown here. Docker images are described in detail later.



endif::showscript[]




:scrollbar:
:data-uri:

== How Containers Differ From VMs

* *Virtual machine* - Each virtualized application includes the application, binaries, libraries, and entire guest operating system

* *Container (Docker)* - Contains just the application and its dependencies 

+
image::images/VMvsContainer.png[]


ifdef::showscript[]

=== Transcript

There are differences between virtual machines and containers. Many people like to bundle them together, but there are important differences. 

Each virtualized application includes not only the application and the necessary binaries and libraries, which may only require 10s of MBs,  but also an entire guest operating system, which may weigh 10s of GBs.

The Docker Engine container comprises just the application and its dependencies. It runs as an isolated process in user space on the host operating system, sharing the kernel with other containers. Thus, it enjoys the resource isolation and allocation benefits of VMs, but is much more portable and efficient.

endif::showscript[]



:scrollbar:
:data-uri:
== Docker Components

* *Docker daemon* - Runs on a host machine 
* *Docker client* - Primary user interface to Docker 
* *Docker images* - Read-only template 
* *Docker registries* - Hold images 
* *Docker containers* - Hold everything needed for application to run


ifdef::showscript[]

=== Transcript

The Docker daemon runs on a host machine. You do not directly interact with the daemon. Instead, you interact through the Docker client.

The Docker client is the primary user interface to Docker. It accepts commands from the user and communicates back and forth with a Docker daemon.

A Docker image is a read-only template. For example, an image could contain a Red Hat Enterprise Linux 7 operating system with Apache and your web application installed.

Docker registries hold images. Registries are public or private stores from which you upload or download images.

Docker containers hold everything that is needed for an application to run. Each container is created from a Docker image. Docker containers can be run, started,
 stopped, moved, and deleted. Each container is an isolated and secure application platform.



endif::showscript[]




:scrollbar:
:data-uri:
== Docker Capabilities

// ISSUE : Introduction to Docker, Slide "Docker Capabilities", do we want to say what it can't do?


* Build Docker images that hold applications
* Create containers from images to run applications
* Share and reuse images via Docker Hub or your registry

ifdef::showscript[]

=== Transcript

With Docker you can build Docker images that hold your applications and create Docker containers from those Docker images to run your applications.
You can share and reuse those Docker images via Docker Hub or your own registry.


endif::showscript[]




:scrollbar:
:data-uri:
== How Does a Docker Image Work


* Read-only templates from which containers are launched
* Each image consists of a series of layers 
* Uses union file system
** Combines layers into single image
** Allows branches to form single file system
* When you change a Docker image, a new layer gets built

ifdef::showscript[]

=== Transcript

Docker images are read-only templates from which Docker containers are launched. Each image consists of a series of layers. 
Docker makes use of union file systems to combine these layers into a single image.

Union file systems also allow files and directories of separate file systems, known as branches, to be transparently overlaid to form a single coherent file system. 

When you change a Docker image—for example, when you update an application to a new version—a new layer gets built. You do not need to distribute a whole new image, just the update.


endif::showscript[]



:scrollbar:
:data-uri:
== What is Kubernetes

* *Kubernetes* - Open source system for managing containerized applications across multiple hosts

* Provides basic mechanisms for deployment, maintenance, and scaling of applications
** *Lean* - Lightweight, simple, accessible
** *Portable* - Public, private, hybrid, multi-cloud
** *Extensible* - Modular, pluggable, hookable, composable
** *Self-healing* - Autoplacement, autorestart, autoreplication

* Builds on over 1.5 decades of experience at Google
+
link:https://github.com/googlecloudplatform/kubernetes[https://github.com/googlecloudplatform/kubernetes]




ifdef::showscript[]

=== Transcript

Next we take a look at the Kubernetes infrastructure. 
Kubernetes is an open source system for managing containerized applications across multiple hosts. It provides basic mechanisms for deployment, maintenance, and scaling of applications.

Kubernetes is lean, portable, extensible, and self-healing. Kubernetes builds upon a decade and a half of experience at Google.

endif::showscript[]




:scrollbar:
:data-uri:
== Kubernetes Concepts

* *Nodes* - Compute resources on top of which containers are built
* *Pods*  - Colocated group of containers with shared storage volumes
* *Replication controllers* - Manage lifecycle of pods
* *Services* - Provide a single, stable name and address for a set of pods 
* *Labels* - Organize and select groups of objects based on key-value pairs


ifdef::showscript[]

=== Transcript

Nodes are the compute resources on top of which your containers are built.

Pods, used in the same context as "a pod of whales" or "peas in a pod", are a colocated group of containers with shared storage volumes. 
Pods are the smallest deployable units that can be created, scheduled, and managed with Kubernetes.

Replication controllers manage the lifecycle of pods. They ensure that a specified number of pods are running at any given time by creating or killing pods as required.

Services provide a single, stable name and address for a set of pods. They act as basic load balancers.

Labels are used to organize and select groups of objects based on key-value pairs.

endif::showscript[]


:scrollbar:
:data-uri:
== Pods

* Correspond to colocated group of applications running with shared context
** May have individual cgroup isolations applied
* Models an application-specific logical host in a containerized environment
** May contain one or more applications that are relatively tightly coupled
** Example: Web server and a “file puller/syncer”
* Smallest deployable units that can be created, scheduled, and managed
* Consist of colocated group of Docker containers with shared volumes
+
image::images/Pods.png[]

ifdef::showscript[]

=== Transcript

A pod corresponds to a colocated group of applications running with a shared context.  Within that context, the applications may also have individual cgroup isolations applied. A pod models an application-specific logical host in a containerized environment. 
A pod may contain one or more applications that are relatively tightly coupled. For example, a Pod could contain a web server and a “file puller/syncer.” In a pre-container world, they would have executed on the same physical or virtual host.
 
In Kubernetes, rather than individual application containers, pods are the smallest deployable units that can be created, scheduled, and managed. 
In terms of Docker constructs, a pod consists of a colocated group of Docker containers with shared volumes.


endif::showscript[]



:scrollbar:
:data-uri:
== OpenShift Enterprise Networking

* Container networking based on integrated Open vSwitch
* Platform-wide routing tier 
* Ability to plug in third-party software-defined network solutions
* Integrated with DNS and existing routing and load-balancing

ifdef::showscript[]

=== Transcript

OpenShift Enterprise provides many networking capabilities based on the integrated Open vSwitch technologies in Red Hat Enterprise Linux. 
It provides a platform-wide routing tier to route traffic to applications. You can also integrate OpenShift Enterprise with third-party SDN solutions and your existing DNS, routing, and load-balancing methods.

endif::showscript[]



:scrollbar:
:data-uri:

== Networking Workflow


// ISSUE : Networking in OpenShift Enterprise v3, Slide: OpenShift Networking - Workflow - Would be great to have an animation for this
// ISSUE : Networking in OpenShift Enterprise v3, Slide: OpenShift Networking - Workflow - Image is wrong "MyDomain.org" != "foodomain.com"

.Scenario: Client points home browser to `myApp.MyDomain.org:80`
* DNS resolves to host running router container
* Using `openshift-sdn` overlay network:
** Router container resolves
** Proxies request to internal pod IP:port (10.1.2.3:8080 )
+
image::images/NetworkScenario01.png[]

ifdef::showscript[]

=== Transcript

Let's review the following scenario:
When a user requests a page, by pointing his or her browser to http://Myapp.MyDomain on port 80, DNS resolves that request to the IP address of one of the nodes that hosts the routing layer.

You would usually create a wildcard Cname record in your DNS server and point it to the node or nodes that host the router container.

The routing layer, in this case the Router Container, then determines which pod should get the request and acts as a proxy for the pod. 

endif::showscript[]



:scrollbar:
:data-uri:
== Container Registry

* Fully integrated Docker v2 registry
* Authentication and access control to images
* Integrates with Red Hat Satellite Server container registry
* Integrates with Docker Hub and other registries

* Image source any server implementing Docker registry API:
** Canonical Docker Hub
** Private registries run by third parties
** Integrated OpenShift Enterprise registry


ifdef::showscript[]

=== Transcript

The next section of this module looks at the Image repository. 

The container, or image, registry is a fully integrated Docker v2 registry. 
It provides authentication and access control to images and can be integrated into the Red Hat Satellite Server container registry. You can also integrate the registry with third-party providers to leverage innovation from the community and ISVs.

OpenShift Enterprise uses any server implementing the Docker registry API as a source of images, including canonical Docker Hub, private registries run by third parties, 
and the integrated OpenShift Enterprise registry.


endif::showscript[]




:scrollbar:
:data-uri:
== Integrated Registry

* Provides an integrated Docker registry 
* Provides place for builds to push images


ifdef::showscript[]

=== Transcript

OpenShift Enterprise provides an integrated Docker registry. This allows users to automatically have a place to which their builds can push the resulting images. Whenever a new image is pushed to the integrated registry, the registry notifies OpenShift Enterprise about the new image and passes along image information, such as the namespace, the name, and the image metadata.

Various pieces of OpenShift Enterprise react to the new images by creating new builds and deployments.

endif::showscript[]




:scrollbar:
:data-uri:
== Third-Party Registries


* Provide builder images, complete application images, and more
* Supportability falls on their respective creators
* Can be polled for changes to image repositories
+
[NOTE]
Polling is not currently implemented.

ifdef::showscript[]

=== Transcript

OpenShift Enterprise can use third-party registries to obtain builder images, complete application images, and more. 
Supportability of these images and registries falls to their respective creators.

OpenShift Enterprise can poll the other registries for changes to image repositories.


endif::showscript[]



:scrollbar:
:data-uri:
== What is an STI Build

* Integrated Docker registry and automated image builds
* Source code deployments leverage *source-to-image (STI)* build automation
* Binary deployments integrate with existing build and CI infrastructure
* Configurable deployment patterns (rolling, etc.)
+
image::images/DockerVsSTIBuilds.png[]


ifdef::showscript[]

=== Transcript

In the final portion of this module, we look at builds and OpenShift STI images. 

The STI build process is a process in which a developer points to a code repository in any of the supported frameworks and selects a builder image that would contain the operating system and framework to support the code. OpenShift Enterprise then creates an image based on the builder image that contains the selected code.

endif::showscript[]



:scrollbar:
:data-uri:
== Why Use STI Builds


* Provides a developer-centric flow 
** Focuses on turning source code into running application
** STI project aims to combine source code with image containing a build and runtime environment

* Strong separation between source code and runtime environment in Docker image helps migrate code between:

** Runtime environments 
** Across major versions of a runtime 
** Across operating system versions 


ifdef::showscript[]

=== Transcript

OpenShift Enterprise v3 provides a developer-centric flow that focuses on turning developer's source code into a running application as simply as possible. 

The Source-to-Image project was started to make it easy for developers to take source code and combine it with an image, called a builder image. 
The builder image contains both a build and runtime environment for that source code.

Having a strong separation between source code, or even binary artifacts, and the runtime environment in the Docker image helps you migrate your code between:

* Runtime environments like Tomcat and other JEE servers, 
* Across major versions of a runtime like Ruby 1.9 and Ruby 2.0, 
* And even across operating system versions like CentOS and Red Hat Enterprise Linux.

endif::showscript[]


:scrollbar:
:data-uri:
== Summary

* Overview and design concepts in OpenShift Enterprise v3 
* Introduction to Docker
* Introduction to Kubernetes infrastructure 
* Networking in OpenShift Enterprise v3
* Image registry 
* Builds and OpenShift STI images


ifdef::showscript[]

=== Transcript

This module presented the following topics:

* Overview and design concepts in OpenShift Enterprise v3, including the OpenShift stack, how OpenShift works, standards, important projects, workflows, and how the various components work.
    
* It introduced Docker, including the difference between containers and VMs, and Docker components and capabilities.

* Next it covered Kubernetes features and concepts with an emphasis on pods. 
 
* It covered an Overview of Networking in OpenShift Enterprise v3, 

* The Image registry section described the integrated OpenShift registry and third-party registries.
 
* And Builds and OpenShift STI images were explained briefly covering what an STI build is and why to use it.

endif::showscript[]




























