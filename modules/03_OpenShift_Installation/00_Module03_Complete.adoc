
== &nbsp;
:noaudio:

ifdef::revealjs_slideshow[]
[#cover,data-background-image="image/1156524-bg_redhat.png" data-background-color="#cc0000"]


[#cover-h1]
Red Hat OpenShift Enterprise Implementation

[#cover-h2]
OpenShift 3.0 Installation

[#cover-logo]
image::{revealjs_cover_image}[]

endif::[]






== Module Topics
:noaudio:
:numbered!:
* Installation Overview
* Prepare your Hosts
* Installation Methods
* Scheduler - Regions and Zones
* The Registry and Router
* Populating OpenShift
* Lab : Install OpenShift Using the installer
* Lab : Regions and Zones
* Lab : The Registy and Router
* Lab : Populating OpenShift


ifdef::showscript[]

=== Transcript
Welcome to Module 3 of the OpenShift Enterprise Implementation course.



endif::showscript[]



== Installation Scenario
:noaudio:

* In this training we will review the install of the following environment

** Master00 [192.168.0.100] - Our master will host the Web Console, The API service and the ETCd DB.
*** Labels : Region=*Infra*, Zone=*NA*, schedulable=`*false*`
** InfraNode00 [192.168.0.101] - The InfraNode0 is to be used only to host "Infrastructure" containers such as the *Registry* and our HAproxy *Router*.
*** Labels : Region=*Infra*, Zone=*infranode*, schedulable=*true*
** Node00 [192.168.0.200] - Part of the Primary Region, Will co-host all the user workloads.
*** Labels : Region=*Primary*, Zone=*East*, schedulable=*true*
** Node01  [192.168.0.201] - Part of the Primary Region, Will co-host all the user workloads.
*** Labels : Region=*Primary*, Zone=*West*, schedulable=*true*
** oselab  [192.168.0.254] - This server will simulate our corporate DNS server that will point our wildcard entry to our HAproxy *router* (that lives on Infranode)
*** Not part of the OpenShift Cluster.



ifdef::showscript[]

=== Transcript

endif::showscript[]

== Installation Methods
:noaudio:

* Currently, There are two types of install methods you can use:
** *Quick Install* - The quick installation method allows you to use an interactive CLI utility to install OpenShift across a set of hosts. The utility is a self-contained wrapper intended for usage on a Red Hat Enterprise Linux 7 host, available at link:https://install.openshift.com[https://install.openshift.com].
** *Advanced Install* - For more complex environments where deeper customization of installation and maintenance is required, an installation process using Ansible playbooks is available. Familiarity with Ansible is assumed.

* In this training we will focus on the Quick Install Method.

ifdef::showscript[]

=== Transcript

endif::showscript[]




== Installation Workflow
:noaudio:

* Prerequisites

** System Requirements
** DNS Setup
** Host Preparation

* OpenShift Installation

** Downloading and Running the Installation Utility

* Post-Install tasks

** Deploy an integrated Docker registry.
** Deploy an HAProxy router.
** Populate your OpenShift installation with image streams and templates.
** Configure authentication and create project for your users.

ifdef::showscript[]
=== Transcript

endif::showscript[]




== Prerequisites
:noaudio:

.System Requirements

* The following are the recommended system requirements for an OpenShift deployment.

* Masters
** Physical or virtual system
** Base OS: Red Hat Enterprise Linux (RHEL) 7.1 with "Minimal" installation option
** 2 vCPU
** Minimum 8 GB RAM
** Minimum 30 GB hard disk space

* Nodes

** Physical or virtual system, or an instance running on a public IaaS
** Base OS: Red Hat Enterprise Linux (RHEL) 7.1 with "Minimal" installation option
** Docker 1.6 or later
** 1 vCPU
** Minimum 8 GB RAM
** Minimum 15 GB hard disk space

* In our learning environment the servers are not configured with the recommended settings to lower costs.


ifdef::showscript[]
=== Transcript


endif::showscript[]

== Prerequisites
:noaudio:

.DNS Setup

* A wildcard for a DNS zone must ultimately resolve to the IP address of the OpenShift router.
* For example, create a wildcard DNS entry for cloudapps, or something similar, that has a low TTL and points to the public IP address of the host where the router will be deployed:
+
----
*.cloudapps.example.com. 300 IN  A 192.168.133.2
----

* In almost all cases, when referencing VMs you must use host names, and the host names that you use must match the output of the hostname -f command on each node.



ifdef::showscript[]

=== Transcript

endif::showscript[]


== Host Preparation
:noaudio:

.Host Preparation - overview

* To prepare your hosts for OpenShift 3 Enterprise
** *Installing Red Hat Enterprise Linux 7.1* - A base installation of `Red Hat Enterprise Linux (RHEL) 7.1` is required for master or node hosts. See the link:https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Installation_Guide/index.html[Red Hat Enterprise Linux 7.1 Installation Guide]
 for more information.
** *Registering the Hosts with subscription-manager - You will need to register all the hosts to RHEL7.1 and OpenShift Enterprise repositories.
** *Managing Base Packages* - You will need to install some utility packages (i.e git, net-tools, bind-utils, iptables-services
** *Managing Services - You will need to disable firewalld and enable iptables-services
** *Install Docker 1.6.x* - Docker version 1.6 or later needs to be installed and storage backend configured for images.
** *Host Password-less communication* - You will ensure that the master hosts can issue remove commands on the nodes without requiring a password.

ifdef::showscript[]

=== Transcript

endif::showscript[]

== Host Preparation
:noaudio:

. Host Preparation - Password-less communication

.Ensuring Installer Access to Hosts
* Ansible, which is used to run the installation process, requires a user that has access to all hosts. For running the installer as a non-root user, passwordless sudo rights must also be configured on each destination host.
* For example, you can generate an SSH key on the host where you will invoke the installation process:
+
----
# ssh-keygen
----

NOTE: Do not use a password.

** An easy way to distribute your SSH keys is by using a bash loop:
+
----
# for host in ose3-master.example.com \
    ose3-node1.example.com \
    ose3-node2.example.com; \
    do ssh-copy-id -i ~/.ssh/id_rsa.pub $host; \
    done
----

NOTE: Modify the host names in the above command according to your configuration.

ifdef::showscript[]

=== Transcript

endif::showscript[]

== Host Preparation
:noaudio:

.Host Preparation - Firewalls
OpenShift relies heavily on iptables under the covers. As such, it must be running, and various ports will need to be opened to allow communication between OpenShift components.

* Ports
** Node-To-Node
*** 4789 : required between nodes for SDN communication between pods on separate hosts

** Nodes-To-Master
*** 53: DNS services within the environment
*** 4789 : required between nodes for SDN communication between pods on separate hosts
*** 8443 : Access to the API

** Master-To-Node
*** 10250 : endpoint for master communication with nodes
*** 4789 : required between nodes for SDN communication between pods on separate hosts

** Master to Master
*** 4789 : required between nodes for SDN communication between pods on separate hosts

** External - Master
*** 8443: CLI and IDE plugins communicate via REST to this port. Web console runs on this port.

ifdef::showscript[]

=== Transcript

endif::showscript[]



== Host Preparation
:noaudio:

.Host Preparation - Networking and misc

* You would need to install the following software packages
+
----
# yum install wget git net-tools iptables-services ython-virtualenv gcc
----

*  Update your software before installation
+
----
# yum update -y
----

ifdef::showscript[]

=== Transcript

endif::showscript[]




== Docker Install
:noaudio:


* Docker version 1.6 or later from the rhel-7-server-ose-3.0-rpms repository must be installed and running on master and node hosts before installing OpenShift.
* We will run through the following procedure:
** Install Docker:
+
----
# yum install docker
----

** Edit the /etc/sysconfig/docker file and add --insecure-registry 172.30.0.0/16 to the OPTIONS parameter. For example:
+
----
OPTIONS=--selinux-enabled --insecure-registry 172.30.0.0/16
----

** The --insecure-registry option instructs the Docker daemon to trust any Docker registry on the 172.30.0.0/16 subnet, rather than requiring a certificate.



NOTE: After installing OpenShift, you can choose to link:https://access.redhat.com/beta/documentation/en/openshift-enterprise-30-administrator-guide/chapter-1-installation#securing-the-registry[secure the integrated Docker registry], which involves adjusting the --insecure-registry option accordingly.


ifdef::showscript[]

=== Transcript

endif::showscript[]



== Docker Install
:noaudio:

.Configuring Docker Storage

* Docker’s default loopback storage mechanism is not supported for production use and is only appropriate for proof of concept environments. For production environments, you must create a thin-pool logical volume and re-configure docker to use that volume.
* You can use the docker-storage-setup script to create a thin-pool device and configure docker’s storage driver after installing docker but before you start using it.
* The script reads configuration options from the /etc/sysconfig/docker-storage-setup file.
* Configure *docker-storage-setup* script for your environment. There are three options available based on your storage configuration:
** Create a thin-pool volume from the remaining free space in the volume group where your root filesystem resides; this requires no configuration:
+
----
# docker-storage-setup
Use an existing volume group, in this example docker-vg, to create a thin-pool:

# echo <<EOF > /etc/sysconfig/docker-storage-setup
VG=docker-vg
SETUP_LVM_THIN_POOL=yes
EOF
# docker-storage-setup
----

** Use an unpartitioned block device to create a new volume group and thinpool. In this example, the /dev/vdc device is used to create the docker-vg volume group:
+
----
# cat <<EOF > /etc/sysconfig/docker-storage-setup
DEVS=/dev/vdc
VG=docker-vg
SETUP_LVM_THIN_POOL=yes
EOF
# docker-storage-setup
----


** Verify your configuration. You should have dm.thinpooldev value in the /etc/sysconfig/docker-storage file and a docker-pool device:
+
----
# lvs
LV                  VG        Attr       LSize  Pool Origin Data%  Meta% Move Log Cpy%Sync Convert
docker-pool         docker-vg twi-a-tz-- 48.95g             0.00   0.44

# cat /etc/sysconfig/docker-storage
DOCKER_STORAGE_OPTIONS=--storage-opt dm.fs=xfs --storage-opt
dm.thinpooldev=/dev/mapper/docker--vg-docker--pool

----

WARNING: This will destroy any docker containers or images currently on the host.

* Re-initialize docker
----
# systemctl stop docker
# rm -rf /var/lib/docker/*
# systemctl restart docker
----


ifdef::showscript[]

=== Transcript

endif::showscript[]





== Installing OpenShift
:noaudio:

* The quick installer is provided at https://install.openshift.com. Visit that page for the latest information and to download the portable version if neccessary.

* There are two methods for using the installation utility.
** Method 1: Running the Installation Utility From the Internet
*** Run the installation utility directly from the Internet by executing the following command on a host that has SSH access to your intended master and node hosts:
+
----
$ sh <(curl -s https://install.openshift.com/ose/)
----

*** Follow the on-screen instructions to install a new OpenShift instance.

** Method 2: Downloading and Running the Installation Utility
*** Download and unpack the installation utility on a host that has SSH access to your intended master and node hosts:
+
----
$ curl -o oo-install-ose.tgz \
    https://install.openshift.com/portable/oo-install-ose.tgz
$ tar -zxf oo-install-ose.tgz
Execute the installation utility to interactively configure one or more hosts:

$ ./oo-install-ose
----

*** Follow the on-screen instructions to install a new OpenShift instance.

* The installer will ask you for Internal and Public IPs of your Masters and Nodes and will configure them accordingly.

ifdef::showscript[]

=== Transcript

endif::showscript[]




== Regions and Zones
:noaudio:

* In OpenShift 2, we introduced the specific concepts of "regions" and "zones" to enable organizations to provide some topologies for application resiliency.
** Apps would be spread throughout the zones within a region and, depending on the way you configured OpenShift, you could make different regions accessible to users.
* penShift 3 doesn’t actually care about your topology or is "topology agnostic".
* OpenShift 3 provides advanced controls for implementing whatever topologies you can dream up.
** You can manipulate filtering and affinity rules to ensure that parts of applications (pods) are either grouped together or spread apart.
** For the purposes of a simple example, we’ll be sticking with the "regions" and "zones" theme. (But think of other option you can up with, "Prod and Dev", "Secure and Insecure", "Rack and Power")
* The assignments of "regions" and "zones" at the node-level are handled by labels on the nodes.
+
----
# oc label node master00-$guid.oslab.opentlc.com region="infra" zone="na"
# oc label node infranode00-$guid.oslab.opentlc.com region="infra" zone="infranodes"
# oc label node node00-$guid.oslab.opentlc.com region="primary" zone="east"
# oc label node node01-$guid.oslab.opentlc.com region="primary" zone="west"
----

ifdef::showscript[]

=== Transcript

endif::showscript[]




== Deploying the Registry
:noaudio:

* OpenShift can build Docker images from your source code, deploy them, and manage their lifecycle. To enable this, an internal, integrated Docker registry can be deployed in your OpenShift environment. OpenShift runs the registry in a pod on a node, just like any other workload.
+
----
$ oadm registry --config=admin.kubeconfig \
    --credentials=openshift-registry.kubeconfig
----

* If you wanted to control where your registry gets deployed, you can specify the labels you want to match.
** This will make sure that the *registry* pod will only be hosted in the "infra" region.
+
----
$ oadm registry --config=admin.kubeconfig \
    --credentials=openshift-registry.kubeconfig \
	   --selector='region=infra'
----

* This creates a service and a deployment configuration, both called docker-registry. Once deployed successfully, a pod is created with a name similar to docker-registry-1-cpty9.

ifdef::showscript[]

=== Transcript

endif::showscript[]




== Deploying the Registry
:noaudio:

.Storage for the Registry

* The registry stores Docker images and metadata. If you simply deploy a pod with the registry, it uses an ephemeral volume that is destroyed if the pod exits. Any images anyone has built or pushed into the registry would disappear.
* For production use, you should use persistent storage using PersistentVolume and PersistentVolumeClaim objects for storage for the registry.
* For non-production use, other options exist to provide persistent storage for the registry, like the --mount-host option.
* We will not cover this topic in this version of the training, it is covered in the link:https://access.redhat.com/beta/documentation/en/openshift-enterprise-30-administrator-guide/chapter-13-persistent-storage-using-nfs[documentation]
ifdef::showscript[]

=== Transcript

endif::showscript[]




== Deploying the Default HAProxy Router
:noaudio:

* The OpenShift router is the ingress point for all traffic destined for services in your OpenShift installation.
* An HAProxy based-router implementation is provided as the default template router plug-in.
** uses the *openshift3/ose-haproxy-router* mage to run an HAProxy instance alongside and a router plug-in.
** currently supports only HTTP(S) traffic and TLS-enabled traffic via SNI.
** is hosted inside OpenShift like any other workload (eg: the registry)
** *While it is called a "router", it is essentially a proxy*.

* The default router’s pod listens on its hosts network interface on port 80 and 443.
** unlike most containers that listen only on private IPs, the default router's container listens on external/public ports.
** The router proxies external requests for route names to the IPs of actual pods identified by the service associated with the route.

ifdef::showscript[]

=== Transcript

endif::showscript[]




== Populating OpenShift
:noaudio:

* You can populate your OpenShift installation with a useful set of Red Hat-provided *image streams* and *templates* to make it easy for developers to create new applications.
** Template: A template describes a set of resources intended to be used together that can be customized and processed to produce a configuration. Each template defines a list of parameters that can be modified for consumption by containers.
** Image Streams: An image stream is similar to a Docker image repository in that it contains one or more Docker images identified by tags. An image stream presents a single virtual view of related images.

* The core set of image streams define images that can be used to build *Node.js*, *Perl*, *PHP*, *Python*, and *Ruby* applications. It also defines images for databases: *MongoDB*, *MySQL*, and *PostgreSQL*.
** To create the core set of image streams, that use the Red Hat Enterprise Linux (RHEL) 7 based images:
+
----
oc create -f \
    examples/image-streams/image-streams-rhel7.json \
    -n openshift
----


ifdef::showscript[]

=== Transcript

endif::showscript[]

== Populating OpenShift
:noaudio:

* The xPaaS Middleware image streams provide images for *JBoss EAP*, *JBoss EWS*, and *JBoss A-MQ*. They can be used to build applications for those platforms.
** To create the Image Streams for xPaaS Middleware Images:
+
----
$ oc create -f \
    examples/xpaas-streams/jboss-image-streams.json
    -n openshift
----
* The database service templates make it easy to run a database instance which can be utilized by other components.
* For each database (*MongoDB*, *MySQL*, and *PostgreSQL*), two templates are provided.
** To create the core set of database templates:
+
----
$ oc create -f \
    examples/db-templates -n openshift
----

** After creating the templates, users are able to easily instantiate the various templates, giving them quick access to a database deployment.


ifdef::showscript[]

=== Transcript

endif::showscript[]




== Populating OpenShift
:noaudio:

* The QuickStart templates define a full set of objects for a running application.
** These Include:
*** Build configurations to build the application from source located in a GitHub public repository
*** Deployment configurations to deploy the application image after it is built.
*** Services to provide load balancing for the application pods.
*** Routes to provide external access to the application.
** To create the core QuickStart templates:
+
----

$ oc create -f \
    examples/quickstart-templates -n openshift

----


ifdef::showscript[]

=== Transcript

endif::showscript[]
